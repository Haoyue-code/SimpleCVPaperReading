# P-DARTS 渐进式搜索

## 1. 引言

在DARTS中，基于梯度下降算法使得神经网络架构的搜索使得其搜索在不消耗大量计算资源的同时，还能得到比较先进的精度。但是通过文章中的结果，也能看出在对搜索出的网络进行迁移和网络架构评估时效果并不好，因此便有研究人员认为其原因是网络架构在搜索时的网络深度和验证时的网络深度不同。

在华为发表在 ICCV 2019上的《Progressive Differentiable Architecture Search: Bridging the Depth Gap between Search and Evaluation》文章中，顾名思义，作者的目的在于解决DARTS中存在着的在代理任务上训练与在目标测试模型的网络深度的不同而带来的问题，并且把所要解决的这一现象称之为Depth Gap，从而提出渐进式增加网络深度的方法。

如图 4-1 所示，在DARTS中，搜索过程中使用的是8 Cells比较浅层的网络架构，而验证时却用20 Cells是更深的网络架构，不能保证在浅层网络中表现好的操作在深层网络中同样出色，从而造成了精度的大幅度下降。但是如果在搜索时就直接采用20 Cells的网络深度，将会导致大量的内存消耗，而且会造成网络架构过拟合的问题，因此P-DARTS则以渐进的方式从5 Cells、11 Cells、17 Cells进行搜索然后采用20 Cells验证，这样更能接近验证时的情况，从而性能也更好。

虽然这种渐进式增加深度的做法能够解决Depth Gap问题，但同时增加了计算负担而且稳定性也降低，因此P-DARTS提出又搜索空间近似策略和搜索空间正则化来做进一步的优化

![渐进式Cell搜索架构](https://img-blog.csdnimg.cn/2e6b02f0dd814e6d9fb09913945617d0.png)

## 2. 搜索空间近似

由于层数增加后，计算量也会随之一并增加，为了解决计算量增大的问题，文章提出搜索空间近似策略，即层数增加的同时，相应地删除训练过程中权值比较小的候选操作，也就是说，网络深度逐渐加深，节点之间连接的可选操作空间逐渐减少。

例如当Cells为5时，每个节点间有5个候选操作，当训练完25个Epoch后，会生成每个操作的权重，接着再进行Cells为11的搜索，显然深度增加了，但这个时候适当删除候选操作中权值低的操作，同样在Cells为17时，也是如此。从而达到节省内存，提升搜索效率的目的。


## 3. 正则化约束

网络在训练过程中为了快速反向传播而往往会倾向于选择跳跃连接，因此在P-DARTS中认为跳跃连接（skip-connection）的欺诈性是导致架构的稳定性比较低主要原因，从而提出对搜索空间做正则化约束的策略来解决该问题。

搜索空间正则化包含了使用Dropout[13]来限制跳跃连接的选择和人为设定跳跃连接的数目两部分。通过Dropout虽然能够阻断跳跃连接来方便算法探索其他操作，但是如果不断地通过阻断跳跃连接选择，最终算法会因为跳跃连接操作的权重过低而被删除，显然会影响最终搜索出来的架构性能。为了解决这种矛盾，文章中通过在训练过程的每个搜索阶段中逐渐衰减Dropout率，使得即使跳跃连接在开始阶段被阻断，在后续阶段中仍能和其他的候选操作平等对待。

另外，人为设定跳跃连接的数目为M，如果最后搜索阶段跳跃连接的数目超过人为设定的值，则搜索该Cell中权重最大的M个跳跃连接并将其他的权重设置为0，然后重新构建Cell。

文章中强调，人为设定跳跃连接数目这一正则化必须建立在使用Dropout限制跳跃连接正则化的基础上，否则会导致搜索所得网络的性能变差。

作者通过对比二阶DARTS与P-DARTS各个阶段搜索出的Cell结构，得出P-DARTS方法搜索到的Cell更深，在验证评估时的效果也更好。







